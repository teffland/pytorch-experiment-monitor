{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch-Monitor walkthrough\n",
    "\n",
    "This notebook serves as an example and test of `pytorch-monitor`.\n",
    "\n",
    "Pytorch is great. Dynamic computation and module composition make rapid prototyping of new deep learning architectures relatively simple. But as many machine learning engineers know, implementation time amounts to a small fraction of development relative to debugging and train/test evaluation.\n",
    "\n",
    "For new architectures, we often want to monitor various metrics during training and testing:\n",
    "* **Model parameter values:** Very large or skewed weight and bias distributions often are a sign of overfitting and small values can be due to underfitting or overregularization.\n",
    "* **Parameter gradient values:** Viewing gradient distributions for model parameters can shed light on vanishing and exploding gradients.  \n",
    "* **Model parameter update dynamics:** Understanding how model parameters change as a result of an optimization step can shed light on optimization issues. Consistently small parameter changes can indicate optimization is suffering from poor conditioning and large update values (especially late in training) often coincide with model performance divergences.\n",
    "* **Intermediate computation activations and gradients:** For deeper or more complicated architectures, it's often useful to monitor intermediate model activation (forward) and jacobian (backward) distributions. This can be crucial in identifying problematic computation nodes and exploding/vanishing gradients.\n",
    "* **Visualization of computation graph:** Visually inspecting the computation graph can be extremely useful in veryifying that your implementation plays out the same way as you drew it on the whiteboard.\n",
    "\n",
    "To monitor these metrics we need:\n",
    "1. Code that indicates the parameters, computations, and gradients to monitor within the model\n",
    "2. Code that writes summaries of these marked computation nodes efficiently to logfiles\n",
    "3. Code that provides an interface for inspecting the logs\n",
    "\n",
    "Tensorboard==1.6 and tensorboardX are great tools for (2) and (3), but the use of tensorboardX for writing summaries of all useful computations (as in (1)) can still be timeconsuming.\n",
    "\n",
    "This is where pytorch-monitor comes in. It's a simple library which aims to do two things:\n",
    "1. Initialize and organize experiment logs easily while encouraging reproducability\n",
    "2. Introspect initialized pytorch `Module`s and endow them with the necessary info to monitor themselves.\n",
    "\n",
    "Our goal is for this process to be fast with sensible defaults, but flexible enough to allow for changes that meet user needs. With pytorch-monitor you can be off the ground monitoring your network behavior in as little as 2 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_monitor import init_experiment, monitor_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: The Basics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the experiment\n",
    "\n",
    "We start by initializing the experiment. Conceptually, an experiment is just the execution of a program and the initial conditions for the program (the `config`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Test Monitor',\n",
       " 'log_dir': 'test',\n",
       " 'run_name': 'May-01-18@12:12:50-dyn-129-236-234-33.dyn.columbia.edu',\n",
       " 'run_dir': 'test/May-01-18@12:12:50-dyn-129-236-234-33.dyn.columbia.edu',\n",
       " 'tag': 'Experiment Config: Test Monitor :: May-01-18@12:12:50\\n'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'title':'Test Monitor',\n",
    "          'log_dir':'test'}\n",
    "writer, config = init_experiment(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot just happened:\n",
    "\n",
    "We've taken the experiment config dictionary and done the following:\n",
    "1. Created a `run_name`\n",
    "2. Created a directory `run_name` in the path `log_dir`\n",
    "3. If you use git to track your code, curent git repository is automatically commited. This ensures a reproducible snapshot of the code used to run the experiment. \n",
    "4. Initialized a tensorboardX `SummaryWriter`.\n",
    "5. Written a text log to tensorboard that has all initial experiment metadata and configuration, such as start time, host name, random seed, hyperparameters, etc. This can be a very useful when comparing multiple runs in tensorboard.\n",
    "6. If a `random_seed` is provided, we've set the random seed for python, numpy, and torch all at once.\n",
    "7. Dumped the config dictionary to file in the `log_dir` as `config.json`.\n",
    "8. Returned the summary writer and config dictionary, augmented with the `run_name`, `run_dir`, and `tag`.\n",
    "\n",
    "I've found this initialization strategy to be comprehensive enough for my needs, but I'm sure it could be better. Submit an issue or pull request if you have suggestions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll create a simple nonlinear 1-d regression in pytorch. It will take a scalar input x, run it through a nonlinear layer, and produce a scalar output.\n",
    "\n",
    "We'll train it to predict the sine function. $y = sin(x)$\n",
    "\n",
    "To do this, first we need some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "sb.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also generate some simple data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get inputs and gold outputs\n",
    "x = 2 * 3.1415 * torch.rand(100,1)\n",
    "y = x.sin()\n",
    "\n",
    "plt.scatter(x.numpy(), y.numpy())\n",
    "_ = plt.title('Gold Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement the model. Our model is a simple neural network with one hidden layer of dimension $H$. Mathematically we implement:\n",
    "\n",
    "$$\\hat{y} = W_2 tanh( W_1 x + b_1) $$\n",
    "where $W_1 \\in \\mathbb{R}^{H \\times 1}$, $b_1 \\in \\mathbb{R}^{H}$ and $W_2 \\in \\mathbb{R}^{1 \\times H}$, and $tanh$ is the elementwise hyperbolic tangent nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encode = nn.Linear(1, hidden_dim)\n",
    "        self.decode = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.tanh(self.encode(x))\n",
    "        \n",
    "        # Monitor h if we can\n",
    "        if hasattr(self, 'monitor'):\n",
    "            self.monitor('h', h, track_data=True, track_grad=True)\n",
    "            \n",
    "        yhat = self.decode(h)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitoring intermediate computations\n",
    "\n",
    "It's often useful to monitor of the forward and backward passes on intermediate (non-leaf) nodes of model computation.  This can help qualify model behavior at key bottlenecks in complex architectures.\n",
    "\n",
    "With pytorch-monitor, any monitored module and all of its descendent submodules will be endowed with a `monitor` method having the signature:\n",
    "\n",
    "```python\n",
    "monitor(name, tensor, track_data=True, track_grad=True)\n",
    "```\n",
    "\n",
    "Once called on a tensor, the monitor method will automatically track the forward and backward pass on the tensor and log it as `<module_name>/<name>` in tensorboard.\n",
    "\n",
    "One final thing. Pytorch modules don't have the `monitor` method unless they or one of their ancestor modules has been wrapped with `monitor_module` (we'll get to that a little later.) So it is good practice to check that the method exists in your module so the code is compatible with non-monitored networks.\n",
    "\n",
    "In our code above, we monitor the hidden layer value $h = tanh( W_1 x + b_1)$ with:\n",
    "\n",
    "```python\n",
    "if hasattr(self, 'monitor'):\n",
    "    self.monitor('h', h, track_data=True, track_grad=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll instantiate our network and its parameter optimizer, and finally we *monitor* it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model and optimizer to have 10 hidden units\n",
    "model = Model(10)\n",
    "optimizer  = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "# Enable monitoring\n",
    "monitor_module(model, writer, \n",
    "               track_data=True,\n",
    "               track_grad=True,\n",
    "               track_update=True,\n",
    "               track_update_ratio=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitoring the module\n",
    "\n",
    "The `monitor_module` method is the meat of pytorch-monitor. It introspects the model and configures it to automatically log sensible histogram summaries of all parameters and `monitor`ed intermediate computations using the summary writer returned from `init_experiment`. \n",
    "\n",
    "It has the following signature:\n",
    "```python\n",
    "monitor_module(model, writer, \n",
    "               track_data=True,\n",
    "               track_grad=True,\n",
    "               track_update=True,\n",
    "               track_update_ratio=False)\n",
    "```\n",
    "\n",
    "Specifically, by using this function we have:\n",
    "1. Added extra datastructures and methods to the module, enabling it to properly manage its monitoring state.\n",
    "2. Added the `monitor` method to all submodules of the module, enabling the monitoring of intermediate computations.\n",
    "3. Registered function hooks on the parameters and monitored tensors of the module and its submodules. These allow for tensorboard summaries of the various tensors to be logged seamlessly to tensorboard. All `Parameters` are monitored according to the keyword arguments of `monitor_module`. All intermediate tensors are monitored according to their respective `monitor` keywords.\n",
    "\n",
    "The keyword arguments allow us to customize what we track about the parameters of the model. (Note: Currently we do not allow for tracking different aspects for different parameters, but could be an easy improvement.)\n",
    "\n",
    "Typically only `track_data` and `track_grad` are necessary, but sometimes it can be useful to monitor module update dynamics with `track_update` and `track_update_ratio`. Specifically, `track_update` will show the true difference in model parameter values from one step to the next. This can shed light on how complex optimizers (such as Adam) are actually affecting the model during training, where the gradient histograms can often be a misleading signal of training behavior because of other update variables like momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitoring during training\n",
    "\n",
    "Finally we'll train the model to minimize the mean squared error of its predictions with the true outputs.\n",
    "\n",
    "During training, we use the summary writer from `init_experiment` to monitor other useful data, such as the loss, and an example of the computation graph on the first run. Check out the [tensorboardX docs](http://tensorboard-pytorch.readthedocs.io/en/latest/tensorboard.html) for a full list of the summary writer's functionality.\n",
    "\n",
    "The pytorch-monitor logging of parameter and intermediate tensors can be relatively time-consuming because it calculates many histograms. During long training processes this can significantly increase training time.  Monitoring the network behavior at *every* iteration, however, usually isn't necessary, so we'd like to be able to turn monitoring on and off selectively. \n",
    "\n",
    "This is why `monitor_module` also sets a `monitoring` method on the model that can be used to toggle the monitoring hooks.  In the example below, we only monitor the network every 500 steps. This is implemented in the lines:\n",
    "\n",
    "```\n",
    "if i % monitor_every == 0:\n",
    "    model.monitoring(True)\n",
    "else:\n",
    "    model.monitoring(False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ... 500 ... "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "nepochs = 3001\n",
    "monitor_every = 500\n",
    "\n",
    "# Plot the models initial predictions\n",
    "_, (ax0, ax1) = plt.subplots(1,2, figsize=(12,4))\n",
    "ax1.scatter(x.numpy(), y.numpy(), label='Truth', s=25, marker='^')\n",
    "\n",
    "# Train the model for nepochs\n",
    "for i in range(nepochs):\n",
    "    \n",
    "    # Save the computation graph for the first iteration\n",
    "    if i == 0:\n",
    "        writer.add_graph(model, x)\n",
    "        \n",
    "    # We only monitor network forward/backward passes \n",
    "    # occasionally for efficiency\n",
    "    if i % monitor_every == 0:\n",
    "        model.monitoring(True)\n",
    "        print(i,'...', end=' ')\n",
    "    else:\n",
    "        model.monitoring(False)\n",
    "        \n",
    "    # Run the model, calculate loss, take a training step\n",
    "    yhat = model(x)\n",
    "    loss = ((yhat - y)**2).mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Log loss values\n",
    "    losses.append(loss.item())\n",
    "    writer.add_scalar('train loss', loss.item(), i)\n",
    "    \n",
    "    # Plot predictions at intermediate steps\n",
    "    if i % (nepochs//2) == 0:\n",
    "        ax1.scatter(x.numpy(), yhat.detach().numpy(), label='Step {}'.format(i), s=20)\n",
    "\n",
    "# Plot the learning curve and sample predictions\n",
    "ax0.plot(list(range(len(losses))), losses)\n",
    "ax0.set_title('Loss during training')\n",
    "ax1.set_title('Predictions During Training')\n",
    "_ = ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
